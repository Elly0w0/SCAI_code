{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Preview: Immune and Inflammatory Response ===\n",
      "- 1, ADP-ribosyl Cyclase\n",
      "- 1, IFN-gamma Receptor\n",
      "- 120a Antigen, CD\n",
      "- 120b Antigen, CD\n",
      "- 12E7 Antigen\n",
      "- 12E7 Protein\n",
      "- 19S Gamma Globulin\n",
      "- 2, C-EBP-Related Protein\n",
      "- 23-C-EBP Protein\n",
      "- 28 kDa Protein, Adipocyte\n",
      "- 293 Cell, HEK\n",
      "- 293 Cells, HEK\n",
      "- 293T Cell\n",
      "- 293T Cells\n",
      "- 4 1BB Receptor\n",
      "- 4 1BB Receptors\n",
      "- 4-1BB Receptor\n",
      "- 4-1BB Receptors\n",
      "- 40-C-EBP Protein\n",
      "- 4F2 Antigen\n",
      "- 4F2 Antigen, Human\n",
      "- 4F2-antigen\n",
      "- 60B8 A Antigen\n",
      "- 60B8 B Antigen\n",
      "- 60B8-A Antigen\n",
      "\n",
      "✅ Extraction complete! Terms saved to: ../data/MeSh_data/mesh_category_terms.json\n"
     ]
    }
   ],
   "source": [
    "# === MeSH-Based Category Keyword Extraction ===\n",
    "\"\"\"\n",
    "Notebook: MeSH_Keyword_Extraction.ipynb\n",
    "Authors: Elizaveta Popova, Negin Babaiha\n",
    "Institution: University of Bonn, Fraunhofer SCAI\n",
    "Date: 09/04/2025\n",
    "\n",
    "Description:\n",
    "    This notebook parses MeSH descriptor data (desc2025.xml) to extract relevant biomedical terms\n",
    "    grouped by conceptual categories related to COVID-19 and neurodegeneration.\n",
    "\n",
    "    Categories include:\n",
    "        1. Viral Entry and Neuroinvasion\n",
    "        2. Immune and Inflammatory Response\n",
    "        3. Neurodegenerative Mechanisms\n",
    "        4. Vascular Effects\n",
    "        5. Psychological and Neurological Symptoms\n",
    "        6. Systemic Cross-Organ Effects\n",
    "\n",
    "    Output:\n",
    "        - mesh_category_terms.json (dictionary of category -> keyword list)\n",
    "\"\"\"\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Load MeSH descriptor file ===\n",
    "tree = ET.parse('../data/MeSh_data/desc2025.xml')  # Update path if necessary\n",
    "root = tree.getroot()\n",
    "\n",
    "# === Define core category-matching keywords (seeds) ===\n",
    "category_keywords = {\n",
    "    \"Viral Entry and Neuroinvasion\": [\n",
    "        \"neuroinvasion\", \"receptor\", \"ACE2\", \"blood-brain barrier\", \"BBB\", \"virus entry\", \"olfactory\", \n",
    "        \"retrograde transport\", \"endocytosis\", \"direct invasion\", \"cranial nerve\", \"neural pathway\", \n",
    "        \"transcribrial\", \"neurotropic\", \"trans-synaptic\", \"neuronal route\", \"olfactory nerve\", \n",
    "        \"hematogenous\", \"choroid plexus\", \"neuronal transmission\", \"entry into CNS\"\n",
    "    ],\n",
    "    \"Immune and Inflammatory Response\": [\n",
    "        \"immune\", \"cytokine\", \"inflammation\", \"interferon\", \"TNF\", \"IL-6\", \"IL6\", \"cytokine storm\", \n",
    "        \"immune response\", \"inflammatory mediators\", \"macrophage\", \"microglia\", \"neutrophil\", \n",
    "        \"lymphocyte\", \"innate immunity\", \"immune dysregulation\", \"chemokine\", \"T cell\", \"NLRP3\", \n",
    "        \"antibody\", \"immune activation\", \"immune imbalance\", \"immune-mediated\", \"complement\"\n",
    "    ],\n",
    "    \"Neurodegenerative Mechanisms\": [\n",
    "        \"neurodegeneration\", \"protein aggregation\", \"apoptosis\", \"cell death\", \"synaptic loss\", \n",
    "        \"neurotoxicity\", \"oxidative stress\", \"mitochondrial dysfunction\", \"tau\", \"amyloid\", \n",
    "        \"α-synuclein\", \"prion\", \"demyelination\", \"neuron loss\", \"misfolded proteins\", \n",
    "        \"chronic neuronal damage\", \"neurodegenerative\", \"neuroinflammation\"\n",
    "    ],\n",
    "    \"Vascular Effects\": [\n",
    "        \"stroke\", \"thrombosis\", \"vascular\", \"ischemia\", \"coagulation\", \"blood clot\", \"microthrombi\", \n",
    "        \"endothelial\", \"vasculitis\", \"hemorrhage\", \"blood vessel\", \"vascular damage\", \"capillary\", \n",
    "        \"clotting\", \"hypoperfusion\", \"angiopathy\", \"vasculopathy\"\n",
    "    ],\n",
    "    \"Psychological and Neurological Symptoms\": [\n",
    "        \"cognitive\", \"memory\", \"fatigue\", \"depression\", \"anxiety\", \"brain fog\", \"psychiatric\", \n",
    "        \"mood\", \"confusion\", \"neuropsychiatric\", \"emotional\", \"behavioral\", \"neurocognitive\", \n",
    "        \"insomnia\", \"psychosocial\", \"attention\", \"motivation\", \"executive function\", \"suicidality\"\n",
    "    ],\n",
    "    \"Systemic Cross-Organ Effects\": [\n",
    "        \"lungs\", \"liver\", \"kidney\", \"systemic\", \"multi-organ\", \"gastrointestinal\", \"heart\", \n",
    "        \"cardiovascular\", \"endocrine\", \"renal\", \"pancreas\", \"organ failure\", \"liver damage\", \n",
    "        \"pulmonary\", \"myocardial\", \"respiratory\", \"hypoxia\", \"oxygen deprivation\", \"fibrosis\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# === Parse MeSH XML and extract matching terms per category ===\n",
    "category_terms = defaultdict(set)\n",
    "\n",
    "for descriptor in root.findall('DescriptorRecord'):\n",
    "    descriptor_name_el = descriptor.find('DescriptorName/String')\n",
    "    if descriptor_name_el is None:\n",
    "        continue\n",
    "\n",
    "    descriptor_name = descriptor_name_el.text\n",
    "    term_elements = descriptor.findall('ConceptList/Concept/TermList/Term/String')\n",
    "    synonyms = [term_el.text for term_el in term_elements if term_el is not None]\n",
    "    all_text = f\"{descriptor_name} \" + ' '.join(synonyms)\n",
    "\n",
    "    for category, keywords in category_keywords.items():\n",
    "        if any(keyword.lower() in all_text.lower() for keyword in keywords):\n",
    "            category_terms[category].update([descriptor_name] + synonyms)\n",
    "\n",
    "# === Convert sets to lists ===\n",
    "for category in category_terms:\n",
    "    category_terms[category] = sorted(list(category_terms[category]))\n",
    "\n",
    "# === Preview sample output ===\n",
    "category_name = \"Immune and Inflammatory Response\"\n",
    "print(f\"=== Preview: {category_name} ===\")\n",
    "for term in category_terms[category_name][:25]:  # Show first 25 terms\n",
    "    print(\"-\", term)\n",
    "\n",
    "# === Export to JSON ===\n",
    "output_path = \"../data/MeSh_data/mesh_category_terms.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(category_terms, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Extraction complete! Terms saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR TESTING API FOR NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding keywords by category...\n",
      "Classifying processes using BERT + Keywords...\n",
      "=== Category Counts (BERT + Keywords) ===\n",
      "Viral Entry and Neuroinvasion: 619\n",
      "Immune and Inflammatory Response: 944\n",
      "Psychological and Neurological Symptoms: 126\n",
      "Uncategorized: 120\n",
      "Vascular Effects: 392\n",
      "Systemic Cross-Organ Effects: 395\n",
      "Neurodegenerative Mechanisms: 265\n",
      "BERT + Keywords classification complete! ✅\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Data\n",
    "df = pd.read_csv('../data/Triples_Final_All_Relevant.csv')\n",
    "\n",
    "with open('../data/MeSh_data/mesh_category_terms.json', 'r') as f:\n",
    "    category_terms = json.load(f)\n",
    "\n",
    "# Step 2: Normalize Process Descriptions and Keywords\n",
    "def normalize_text(text):\n",
    "    text = re.sub(r\"[_\\-]\", \" \", text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df['Normalized_Process'] = df['Pathophysiological Process'].apply(normalize_text)\n",
    "\n",
    "for category in category_terms:\n",
    "    category_terms[category] = [normalize_text(term) for term in category_terms[category]]\n",
    "\n",
    "# Step 3: Initialize BERT Model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Step 4: Embed Category Keywords (Grouped by Category)\n",
    "print(\"Embedding keywords by category...\")\n",
    "\n",
    "category_keyword_embeddings = {}\n",
    "\n",
    "for category, keywords in category_terms.items():\n",
    "    if keywords:\n",
    "        embeddings = model.encode(keywords, convert_to_tensor=True)\n",
    "        category_keyword_embeddings[category] = embeddings\n",
    "    else:\n",
    "        category_keyword_embeddings[category] = None\n",
    "\n",
    "# Step 5: Function to Classify a Single Process\n",
    "def bert_keyword_classify(process_text, category_keyword_embeddings, threshold=0.5, aggregation=\"max\"):\n",
    "    # Embed the process description\n",
    "    process_embedding = model.encode(process_text, convert_to_tensor=True)\n",
    "\n",
    "    best_category = None\n",
    "    best_score = 0.0\n",
    "    category_scores = {}\n",
    "\n",
    "    for category, keyword_embeddings in category_keyword_embeddings.items():\n",
    "        if keyword_embeddings is None or len(keyword_embeddings) == 0:\n",
    "            continue\n",
    "\n",
    "        # Compute cosine similarity between process and all keywords for this category\n",
    "        cosine_scores = util.pytorch_cos_sim(process_embedding, keyword_embeddings)[0]\n",
    "\n",
    "        # Aggregate scores (options: max, mean, etc.)\n",
    "        if aggregation == \"max\":\n",
    "            score = torch.max(cosine_scores).item()\n",
    "        elif aggregation == \"mean\":\n",
    "            score = torch.mean(cosine_scores).item()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported aggregation type. Use 'max' or 'mean'.\")\n",
    "\n",
    "        category_scores[category] = score\n",
    "\n",
    "        # Track best score and category\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_category = category\n",
    "\n",
    "    if best_score >= threshold:\n",
    "        return best_category\n",
    "    else:\n",
    "        return \"Uncategorized\"\n",
    "\n",
    "# Step 6: Apply Classifier to the Dataset\n",
    "print(\"Classifying processes using BERT + Keywords...\")\n",
    "\n",
    "df['Category_BERT_Keywords'] = df['Normalized_Process'].apply(\n",
    "    lambda x: bert_keyword_classify(x, category_keyword_embeddings, threshold=0.5, aggregation=\"max\")\n",
    ")\n",
    "\n",
    "# Step 7: Count Items per Category\n",
    "category_counts = Counter(df['Category_BERT_Keywords'])\n",
    "\n",
    "print(\"=== Category Counts (BERT + Keywords) ===\")\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"{category}: {count}\")\n",
    "\n",
    "# Step 8: Export Results\n",
    "df.to_csv('../data/Triples_Final_All_Relevant_Categorized.csv', index=False)\n",
    "df.to_excel('../data/Triples_Final_All_Relevant_Categorized.xlsx', index=False)\n",
    "\n",
    "counts_df = pd.DataFrame(category_counts.items(), columns=['Category', 'Count'])\n",
    "# counts_df.to_excel('Category_Counts_BERT_Keywords.xlsx', index=False)\n",
    "\n",
    "print(\"BERT + Keywords classification complete! ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
